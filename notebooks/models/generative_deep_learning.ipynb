{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "- Neural Style Transfer\n",
    "- Generative Adversarial Networks (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural Style Transfer in a nutshell\n",
    "\n",
    "- Reproduce an image with a new artistic style provided by another image.\n",
    "- Blend a *content* image and a *style reference* image in a stylized output image.\n",
    "- First described in [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576) by Gatys et al (2015). Many refinements and variations since."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example (Prisma app)\n",
    "\n",
    "[![Prisma style transfer example](images/style_transfer_prisma.png)](https://harishnarayanan.org/writing/artistic-style-transfer/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Underlying idea: loss minimization\n",
    "\n",
    "![Content loss](images/content-loss.png)\n",
    "![Style loss](images/style-loss.png)\n",
    "![Total loss](images/total-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The content loss\n",
    "\n",
    "- Content = high-level structure of an image.\n",
    "- Can be captured by the upper layer of a convolutional neural network.\n",
    "- Content loss for a layer = distance between the feature maps of the content and generated images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The style loss\n",
    "\n",
    "- Style = low-level features of an image (textures, colors, visual patterns).\n",
    "- Can be captured by using correlations across the different feature maps (filter responses) of a convnet.\n",
    "- Feature correlations are computed via a Gram matrix (outer product of the feature maps for a given layer).\n",
    "- Style loss for a layer = distance between the Gram matrices of the feature maps for the style and generated images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The total variation loss\n",
    "\n",
    "- Sum of the absolute differences for neighboring pixel-values in an image. Measures how much noise is in the image.\n",
    "- Encourage spatial continuity in the generated image (denoising).\n",
    "- Act as a regularization loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent\n",
    "\n",
    "- Objective: minimize the total loss.\n",
    "- Optimizer: [L-BFGS](http://aria42.com/blog/2014/12/understanding-lbfgs) (original choice made by Gatys et al.) or Adam.\n",
    "\n",
    "![Animation of style transfer](images/style_transfer_animated.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generative Adversarial Networks (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GAN in a nutshell\n",
    "\n",
    "- Simultaneously train two models:\n",
    "  - One tries to generate realistic data.\n",
    "  - The other tries to discriminate between real and generated data.\n",
    "- Each model is trained to best the other.\n",
    "- First described in [Generative Adversarial Nets\n",
    "](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) by Goodfellow et al. (2014).\n",
    "- [NIPS 2016 Tutorial](https://arxiv.org/abs/1701.00160)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[![GAN overview](images/gan1.png)](https://www.tensorflow.org/tutorials/generative/dcgan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[![GAN process](images/gan2.png)](https://www.tensorflow.org/tutorials/generative/dcgan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training process\n",
    "\n",
    "- The generator creates images from random noise.\n",
    "- Generated images are mixed with real ones.\n",
    "- The discriminator is trained on these mixed images.\n",
    "- The generator's parameters are updated in a direction that makes the discriminator more likely to classify generated data as \"real\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: generate handwritten digits\n",
    "\n",
    "We'll use the MNIST dataset to train the generator and the discriminator. The generator will generate handwritten digits resembling the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.5\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "assert platform.python_version_tuple() >= (\"3\", \"6\")\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 8\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.0.0\n",
      "Keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {tf.keras.__version__}\")\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    BatchNormalization,\n",
    "    LeakyReLU,\n",
    "    Reshape,\n",
    "    Conv2DTranspose,\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    ")\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: (60000, 28, 28). Training labels: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Load only the training set for MNIST\n",
    "(train_images, train_labels), (_, _) = mnist.load_data()\n",
    "\n",
    "print(f\"Training images: {train_images.shape}. Training labels: {train_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Change pixel values from (0, 255) to (0, 1)\n",
    "x_train = train_images.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1) to apply convolution\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "\n",
    "print(f\"x_train: {x_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a generator\n",
    "\n",
    "The generator uses `Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). A `Dense` layer takes this seed as input, then upsamples several times until the desired image size of 28x28x1 is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(\n",
    "        Conv2DTranspose(128, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False)\n",
    "    )\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    model.add(\n",
    "        Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False)\n",
    "    )\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    model.add(\n",
    "        Conv2DTranspose(\n",
    "            1, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False, activation=\"tanh\"\n",
    "        )\n",
    "    )\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "generator = make_generator_model()\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 362
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the (untrained) generator to create an image from noise\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "with sns.axes_style(\"white\"):  # Temporary hide Seaborn grid line\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(generated_image[0, :, :, 0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a discriminator\n",
    "\n",
    "The discriminator is based on a standard CNN architecture. This model will be trained to output positive values for real images, and negative values for fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\", input_shape=[28, 28, 1])\n",
    "    )\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator prediction: 0.00205\n"
     ]
    }
   ],
   "source": [
    "# Classify the first generated image\n",
    "decision = discriminator(generated_image)\n",
    "\n",
    "# Convert TF tensor to scalar\n",
    "print(f\"Discriminator prediction: {np.mean(decision):.05f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discriminator loss\n",
    "\n",
    "This function quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross-entropy loss\n",
    "cross_entropy = BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generator loss\n",
    "\n",
    "This function quantifies how well the generator was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, we will compare the discriminators decisions on the generated images to an array of 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = Adam(1e-4)\n",
    "discriminator_optimizer = Adam(1e-4)\n",
    "\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'clear_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d152560ca122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-802af7bf198a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Produce images for the GIF as we go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     generate_and_save_images(generator,\n\u001b[1;32m     11\u001b[0m                              \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'clear_output'"
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specificities and gotchas\n",
    "\n",
    "- A GAN is a dynamic system that evolves at each training step.\n",
    "- Interestingly, the generator never sees images froms the training set directly: all its informations come from the discriminator.\n",
    "- Training can be tricky: noisy generated data, vanishing gradients, domination of one side...\n",
    "- GAN convergence theory is an active area of research.\n",
    "- [GAN Open Questions](https://distill.pub/2019/gan-open-problems/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GAN progress on face generation\n",
    "\n",
    "[![GAN progress from 2014 to 2018](images/gan_2014_2018.jpg)](https://twitter.com/goodfellow_ian/status/1084973596236144640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The GAN landscape\n",
    "\n",
    "[![GAN flavours](images/gan_flavours.png)](https://blog.floydhub.com/gans-story-so-far/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some GAN flavours\n",
    "\n",
    "- [DCGAN](https://arxiv.org/abs/1511.06434) (2016): use deep convolutional networks for generator and discriminator.\n",
    "- [CycleGAN](https://arxiv.org/abs/1703.10593v6) (2017): image-to-image translation in the absence of any paired training examples.\n",
    "- [StyleGAN](https://arxiv.org/abs/1812.04948) (2019): fine control of output images.\n",
    "- [GAN - The Story So Far](https://blog.floydhub.com/gans-story-so-far/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GAN use cases: not just images!\n",
    "\n",
    "- Writing a novel \"in the style of an author\".\n",
    "- [Generating music](https://arxiv.org/abs/1805.07848) ([samples](https://www.youtube.com/watch?v=vdxCqNWTpUs)).\n",
    "- Generating realistic passwords for hackers.\n",
    "- Generating videos ([example](https://www.youtube.com/watch?time_continue=3&v=ab64TWzWn40&feature=emb_logo)).\n",
    "- [Generating video game levels](https://arxiv.org/abs/1910.01603).\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
