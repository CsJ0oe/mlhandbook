{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Overview\n",
    "- Gradient descent types\n",
    "- Model parameters update\n",
    "- Optimization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An iterative approach\n",
    "\n",
    "The model's parameters are iteratively updated until an optimum is reached.\n",
    "\n",
    "[![Iterative approach](images/GradientDescentDiagram.png)](https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The gradient descent algorithm\n",
    "\n",
    "- Used in several ML models, including neural networks.\n",
    "- General idea: converging to a loss function's minimum by updating model parameters in small steps, in the **opposite direction** of the loss function **gradient**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The notion of gradient\n",
    "\n",
    "- Expresses the variation of a function relative to the variation of its parameters.\n",
    "- Vector containing partial derivatives of the function *w.r.t.* each of its $P$ parameters.\n",
    "\n",
    "$$\\nabla_{\\theta}\\mathcal{L}(\\boldsymbol{\\pmb{\\theta}}) = \\begin{pmatrix}\n",
    "       \\ \\frac{\\partial}{\\partial \\theta_1} \\mathcal{L}(\\boldsymbol{\\theta}) \\\\\n",
    "       \\ \\frac{\\partial}{\\partial \\theta_2} \\mathcal{L}(\\boldsymbol{\\theta}) \\\\\n",
    "       \\ \\vdots \\\\\n",
    "       \\ \\frac{\\partial}{\\partial \\theta_P} \\mathcal{L}(\\boldsymbol{\\theta})\n",
    "     \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1D gradient descent (one parameter)\n",
    "\n",
    "![Gradient Descent](images/gradient_descent_1parameter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2D gradient (two parameters)\n",
    "\n",
    "![Tangent Space](images/tangent_space.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2D gradient descent\n",
    "\n",
    "![Gradient Descent](images/gradient_descent_2parameters.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient descent types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Batch Gradient Descent\n",
    "\n",
    "The gradient is computed on the whole dataset before model parameters are updated.\n",
    "\n",
    "- Advantages: simple and safe (always converges in the right direction).\n",
    "- Drawback: can become slow and even untractable with a big dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "The gradient is computed on only one randomly chosen sample whole dataset before parameters are updated.\n",
    "\n",
    "- Advantages:\n",
    "  - Very fast.\n",
    "  - Enables learning from each new sample (*online learning*).\n",
    "- Drawback:\n",
    "  - Convergence is not guaranteed.\n",
    "  - No vectorization of computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mini-Batch SGD\n",
    "\n",
    "The gradient is computed on a small set of samples, called a *batch*, before parameters are updated.\n",
    "\n",
    "- Combines the advantages of batch and stochastic GD.\n",
    "- Default method for many ML libraries.\n",
    "- The mini-batch size varies between 10 and 1000 samples, depending of the dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model parameters update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning rate\n",
    "\n",
    "$\\eta$ is the update factor for parameters once gradient is computed, called the **_learning rate_**.\n",
    "\n",
    "It has a direct impact on the \"speed\" of the gradient descent.\n",
    "\n",
    "$$\\pmb{\\theta_{next}} = \\pmb{\\theta} - \\eta\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Importance of learning rate\n",
    "\n",
    "![Learning rate](images/learning_rate.png)\n",
    "\n",
    "[Interactive exercise](https://developers.google.com/machine-learning/crash-course/fitter/graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The local minima problem\n",
    "\n",
    "![Local minima](images/local_minima.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Gradient Descent](images/gd_ng.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent evolution map\n",
    "\n",
    "[![Gradient Descent evolution map](images/gradient_descent_evolution_map.png)](https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Momentum\n",
    "\n",
    "Momentum optimization accelerates the descent speed in the direction of the minimum by accumulating previous gradients. It can also escape plateaux faster then plain GD.\n",
    "\n",
    "[![Momemtum demo](images/gd_momentum_demo.gif)](https://youtu.be/qPKKtvkVAjY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Momentum equations\n",
    "\n",
    "$$\\pmb{m_{k+1}} = \\beta_k \\pmb{m_k} - \\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta_k})$$\n",
    "\n",
    "$$\\pmb{\\theta_{k+1}} = \\pmb{\\theta_k} + \\eta_k\\pmb{m_{k+1}}$$\n",
    "\n",
    "$\\beta_k \\in [0,1]$ is a friction factor that prevents gradients updates from growing too large. A typical value is 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Momentum Vs plain GD\n",
    "\n",
    "[![Momentum Vs plain GD](images/gd_momentum.png)](https://youtu.be/kVU8zTI-Od0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RMSprop\n",
    "\n",
    "*RMSprop* decays the learning rate differently for each parameter, scaling down the gradient vector along the steepest dimensions. The underlying idea is to adjust the descent direction a bit more towards the global minimum.\n",
    "\n",
    "$$\\pmb{v_{k+1}} = \\beta_k \\pmb{v_k} + (1-\\beta_k) \\left(\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta_k})\\right)^2$$\n",
    "\n",
    "$$\\pmb{\\theta_{k+1}} = \\pmb{\\theta_k} - \\frac{\\eta_k}{\\sqrt{\\pmb{v_{k}}+\\epsilon}}\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta_k})$$\n",
    "\n",
    "$\\epsilon$ is a smoothing term to avoid divisions by zero. A typical value is $10^{-10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adam and other techniques\n",
    "\n",
    "*Adam* (*Adaptive Moment Estimation*) combines the ideas of momentum and RMSprop. It is the *de facto* choice nowadays.\n",
    "\n",
    "Gradient descent optimization is a rich subfield of Machine Learning. Read more in [this article](http://ruder.io/optimizing-gradient-descent/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
