{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Regression losses\n",
    "- Classification losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.5\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "assert platform.python_version_tuple() >= (\"3\", \"6\")\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 0.22.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "assert sklearn.__version__ >= \"0.22\"  # For plotting API\n",
    "\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean Absolute Error\n",
    "\n",
    "Aka *l1 or Manhattan norm*.\n",
    "\n",
    "$$\\mathrm{MAE}(\\boldsymbol{\\pmb{\\theta}}) = \\frac{1}{m}\\sum_{i=1}^m |\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}) - y^{(i)}| = \\frac{1}{m}{\\lVert{h_\\theta(\\pmb{X}) - \\pmb{y}}\\rVert}_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean Squared Error\n",
    "\n",
    "Most sensible to outliers.\n",
    "\n",
    "$$\\mathrm{MSE}(\\boldsymbol{\\pmb{\\theta}}) = \\frac{1}{m}\\sum_{i=1}^m (\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}) - y^{(i)})^2 = \\frac{1}{m}{{\\lVert{h_\\theta(\\pmb{X}) - \\pmb{y}}\\rVert}_2}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root Mean Squared Error\n",
    "\n",
    "Aka *l2 or Euclidean norm*). The default choice.\n",
    "\n",
    "$$\\mathrm{RMSE}(\\boldsymbol{\\pmb{\\theta}}) = \\sqrt{\\frac{1}{m}\\sum_{i=1}^m (\\mathcal{h}_\\theta(\\mathbf{x}^{(i)}) - y^{(i)})^2} = \\frac{1}{m}{\\lVert{h_\\theta(\\pmb{X}) - \\pmb{y}}\\rVert}_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary Crossentropy\n",
    "\n",
    "Aka *logistic loss* or *negative log likelyhood*. \n",
    "\n",
    "$$\\mathcal{L}(\\boldsymbol{\\pmb{\\theta}}) = -\\frac{1}{m}\\sum_{i=1}^m \\left(y^{(i)} \\log_e(y'^{(i)}) + (1-y^{(i)}) \\log_e(1-y'^{(i)})\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1738073366910675\n",
      "9.992007221626415e-16\n",
      "2.241848548341448\n"
     ]
    }
   ],
   "source": [
    "# Define expected results\n",
    "y_true = [0, 0, 1, 1]\n",
    "\n",
    "# [.9, .1] means 90% probability that the first sample has label 0: prediction is 0.1\n",
    "y_pred = [[0.9, 0.1], [0.8, 0.2], [0.3, 0.7], [0.01, 0.99]]\n",
    "# -(ln(0.9) + ln(0.8) + ln(0.7) + ln(0.99))/4\n",
    "print(log_loss(y_true, y_pred))\n",
    "\n",
    "# Perfect prediction\n",
    "y_pred = [[1, 0], [1, 0], [0, 1], [0, 1]]\n",
    "print(log_loss(y_true, y_pred))\n",
    "\n",
    "# Awful prediction\n",
    "y_pred = [[0.1, 0.9], [0.15, 0.85], [0.83, 0.17], [0.95, 0.05]]\n",
    "print(log_loss(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Categorical Crossentropy\n",
    "\n",
    "$$\\mathcal{L}(\\boldsymbol{\\pmb{\\theta}}) = -\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^K y^{(i)}_k \\log_e(y'^{(i)}_k)$$\n",
    "\n",
    "Equivalent to _Binary Crossentropy_ when $K = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
